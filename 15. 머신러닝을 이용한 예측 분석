ğŸ“˜ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì•Œì•„ë³´ê¸°
âœ… ë¨¸ì‹ ëŸ¬ë‹ì´ë€?
ì˜ˆì¸¡ ë³€ìˆ˜ (Feature): ì…ë ¥ ë°ì´í„°, ì˜ˆ: ë‚˜ì´, ì§ì—…, í•™ë ¥ ë“±
íƒ€ê²Ÿ ë³€ìˆ˜ (Target): ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” ê²°ê³¼, ì˜ˆ: ì†Œë“ ìˆ˜ì¤€
ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸: ê³¼ê±° ë°ì´í„°ë¥¼ í•™ìŠµí•´ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜

ğŸŒ² ì˜ì‚¬ê²°ì •ë‚˜ë¬´(Decision Tree) ëª¨ë¸
âœ… ì •ì˜
ì¡°ê±´ì— ë”°ë¼ ë°ì´í„°ë¥¼ ë¶„í• í•˜ë©° ë¶„ë¥˜í•˜ê±°ë‚˜ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸
ë‚˜ë¬´ì²˜ëŸ¼ ë¶„ê¸°ë˜ëŠ” êµ¬ì¡°ë¡œ ì˜ì‚¬ê²°ì •ì„ ì‹œê°í™”

âœ… ì‘ë™ ì›ë¦¬
íƒ€ê²Ÿ ë³€ìˆ˜ë¥¼ ê°€ì¥ ì˜ ë¶„ë¦¬í•˜ëŠ” ì˜ˆì¸¡ ë³€ìˆ˜ ì„ íƒ
ê·¸ ë³€ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë¶„í• 
ê° ë…¸ë“œì—ì„œ ë°˜ë³µ ë¶„í•  ìˆ˜í–‰
ë” ì´ìƒ ë‚˜ëˆŒ ìˆ˜ ì—†ì„ ë•Œ(ë˜ëŠ” ì¡°ê±´ ë§Œì¡± ì‹œ) ì¢…ë£Œ

âœ… íŠ¹ì§•
ì§ê´€ì ì´ê³  í•´ì„ ì‰¬ì›€
ê³¼ì í•©(overfitting) ìœ„í—˜ ìˆìŒ â†’ max_depth ë“± í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì • í•„ìš”

ğŸ“Š [ì†Œë“ ì˜ˆì¸¡ ëª¨ë¸ ë§Œë“¤ê¸°]
import pandas as pd
df = pd.read_csv('adult.csv')
df.info()

âœ… 1ë‹¨ê³„: ì „ì²˜ë¦¬
# íƒ€ê²Ÿ ë³€ìˆ˜ ì „ì²˜ë¦¬
import numpy as np
df['income'] = np.where(df['income'] == '>50k', 'high', 'low')

# ë¶ˆí•„ìš”í•œ ì—´ ì œê±°
df = df.drop(columns='fnlwgt')

# ë²”ì£¼í˜• ë³€ìˆ˜ â†’ ë”ë¯¸ ë³€ìˆ˜ë¡œ ë³€í™˜
target = df['income']
df = df.drop(columns='income')
df = pd.get_dummies(df)
df['income'] = target

# ì •ë³´ í™•ì¸
df.info(max_cols=np.inf)

âœ… 2ë‹¨ê³„: ë°ì´í„° ë¶„í• 
from sklearn.model_selection import train_test_split

df_train, df_test = train_test_split(df,
                                     test_size=0.3,
                                     stratify=df['income'],
                                     random_state=1234)

ğŸŒ² [ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ëª¨ë¸ ë§Œë“¤ê¸°]
from sklearn import tree

# ëª¨ë¸ ìƒì„±
clf = tree.DecisionTreeClassifier(random_state=1234, max_depth=3)

# í•™ìŠµ
train_x = df_train.drop(columns='income')
train_y = df_train['income']
model = clf.fit(train_x, train_y)

âœ… ëª¨ë¸ ì‹œê°í™”
import matplotlib.pyplot as plt

plt.rcParams.update({'figure.dpi': 100, 'figure.figsize': [12, 8]})

tree.plot_tree(model,
               feature_names=list(train_x.columns),
               class_names=['high', 'low'],
               proportion=True,
               filled=True,
               rounded=True,
               impurity=False,
               label='root',
               fontsize=10)

ğŸ¤– [ëª¨ë¸ì„ ì´ìš©í•´ ì˜ˆì¸¡í•˜ê¸°]
test_x = df_test.drop(columns='income')
test_y = df_test['income']

df_test['pred'] = model.predict(test_x)

ğŸ“ [ì„±ëŠ¥ í‰ê°€í•˜ê¸°]
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import sklearn.metrics as metrics

# í˜¼ë™ í–‰ë ¬
conf_mat = confusion_matrix(y_true=df_test['income'],
                            y_pred=df_test['pred'],
                            labels=['high', 'low'])

# ì‹œê°í™”
ConfusionMatrixDisplay(confusion_matrix=conf_mat,
                       display_labels=['high', 'low']).plot(cmap='Blues')

âœ… ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨, F1-score
# ì •í™•ë„
metrics.accuracy_score(test_y, df_test['pred'])
# ì •ë°€ë„
metrics.precision_score(test_y, df_test['pred'], pos_label='high')
# ì¬í˜„ìœ¨
metrics.recall_score(test_y, df_test['pred'], pos_label='high')
# F1 ìŠ¤ì½”ì–´
metrics.f1_score(test_y, df_test['pred'], pos_label='high')

